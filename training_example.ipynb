{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe541ebd-88ea-45b9-afe9-094284d0fd33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee130e2-5f66-4a88-be9e-304bf5d77a6f",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3445d4-6903-483a-ac43-0430e8c251ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 50\n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-2\n",
    "MAX_SENTENCE_WORDS = \"unbounded\"\n",
    "NR_FROM_EACH_CLASS = 10000\n",
    "N_QUBITS = 2\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ac0b2-e8a4-46d4-96e2-e7db4eeb2219",
   "metadata": {},
   "source": [
    "Native Python libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc47f0b-af6d-4928-9321-e195c484f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295636b0-e950-4d4d-8b0b-fe2dcb9a579c",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f99870a-e30c-41aa-9cb1-94098622edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e461303-d74d-432a-8820-42f631238956",
   "metadata": {},
   "source": [
    "Lambeq imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab870f-5685-4c3d-890e-1ff2e3881802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lambeq\n",
    "from lambeq import SpacyTokeniser\n",
    "from lambeq import Dataset\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72621b29-31ff-437c-867e-88f3878ae82b",
   "metadata": {},
   "source": [
    "Code imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a05823-2467-473b-8a81-a6389a5b3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_model import LinearModel\n",
    "from optax_optimizer import OptaxOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed52f5-55df-4949-afce-cf644e953ecb",
   "metadata": {},
   "source": [
    "**Make this notebook deterministic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d7ea70-4691-4430-b447-1c8051638f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdad6b2-78cf-40ea-bee2-4a019fb15fb0",
   "metadata": {},
   "source": [
    "Set `numpy` options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efbca9f-cdec-4a71-956e-8f8a44093dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, linewidth = 200, threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf37bf-079c-4207-9cac-fde9f98eecad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70719a7a-d0f6-4144-a8f3-e96dc362892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load poetry dataset\n",
    "df_train = pd.read_csv(\"poem_sentiment/train_tokenised.csv\", index_col = 0)\n",
    "df_dev = pd.read_csv(\"poem_sentiment/dev_tokenised.csv\", index_col = 0)\n",
    "df_test = pd.read_csv(\"poem_sentiment/test_tokenised.csv\", index_col = 0)\n",
    "df_list = [df_train, df_dev, df_test]\n",
    "\n",
    "# Change sentiment to correct format and rename columns\n",
    "for df in df_list:\n",
    "    df[\"sentiment\"] = df.sentiment.apply(lambda x: [0., 1.] if x == 1 else [1., 0.])\n",
    "    df.rename({\"sentence\":\"tokenised\", \"sentiment\":\"labels\"}, inplace = True, axis=1)\n",
    "\n",
    "# Truncate sentences if needed \n",
    "df_joined = pd.concat(df_list)\n",
    "max_words = max(df[\"tokenised\"].map(len)) if MAX_SENTENCE_WORDS == \"unbounded\" else MAX_SENTENCE_WORDS\n",
    "for df in df_list:\n",
    "    df[\"tokenised\"] = [x[:max_words] for x in df[\"tokenised\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad756b4-67d8-4767-89f4-4d506edef226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. training sentences:  298\n",
      "Nr. test sentences:  35\n",
      "Nr. validation sentences:  39\n"
     ]
    }
   ],
   "source": [
    "print(\"Nr. training sentences: \", len(df_train))\n",
    "print(\"Nr. test sentences: \", len(df_test))\n",
    "print(\"Nr. validation sentences: \", len(df_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b0179-b3d5-4907-8ab8-cc3026df6556",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14786443-ea41-401b-970f-e34211e81445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from ansatz import _hardware_efficient_ansatz, _trivial_combine, _zero_ket, _multi_cnot_and_measure\n",
    "hea = _hardware_efficient_ansatz(N_QUBITS, LAYERS)\n",
    "initial_state = _zero_ket(N_QUBITS)\n",
    "cnots = _multi_cnot_and_measure(N_QUBITS)\n",
    "model = LinearModel.from_tokenised_sentences(df[\"tokenised\"],\n",
    "                                             initial_state,\n",
    "                                             hea,\n",
    "                                             _trivial_combine,\n",
    "                                             2*N_QUBITS*LAYERS,\n",
    "                                             0,\n",
    "                                             end=cnots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c73b0d-79b2-477c-87cf-257129bb04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda y_hat, y: -jnp.sum(y * jnp.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: jnp.sum(jnp.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "eval_metrics = {\"acc\": acc}\n",
    "\n",
    "trainer = QuantumTrainer(\n",
    "    model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=OptaxOptimizer.get(optax.adam),\n",
    "    #optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'learning_rate': 1e-3},\n",
    "    #optim_hyperparams={'a': 0.05, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a35e2a-f372-4b47-bda7-190b731dea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "            df_train[\"tokenised\"],\n",
    "            df_train.labels,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = Dataset(df_dev[\"tokenised\"], df_dev[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e7ba541-ddcb-49e1-ad16-cc834b816cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate NaN debugging just in case\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887f6bd5-e9bc-4571-bbc6-a8fa684bb35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmatos/phd/projects/linear-model/optax_optimizer.py:107: UserWarning: OptaxOptimizer.state_dict not yet fully implemented\n",
      "  warnings.warn('OptaxOptimizer.state_dict not yet fully implemented')\n",
      "Epoch 1:   train/loss: 0.7875   valid/loss: 0.8437   train/acc: 0.5570   valid/acc: 0.5128\n",
      "Epoch 5:   train/loss: 0.6083   valid/loss: 0.7770   train/acc: 0.6409   valid/acc: 0.5897\n",
      "Epoch 10:  train/loss: 0.5155   valid/loss: 0.7271   train/acc: 0.7416   valid/acc: 0.5385\n",
      "Epoch 15:  train/loss: 0.4769   valid/loss: 0.6888   train/acc: 0.7953   valid/acc: 0.6154\n",
      "Epoch 20:  train/loss: 0.4547   valid/loss: 0.6940   train/acc: 0.8221   valid/acc: 0.6410\n",
      "Epoch 25:  train/loss: 0.4372   valid/loss: 0.7143   train/acc: 0.8356   valid/acc: 0.6410\n",
      "Epoch 30:  train/loss: 0.4225   valid/loss: 0.7449   train/acc: 0.8456   valid/acc: 0.6154\n",
      "Epoch 35:  train/loss: 0.4106   valid/loss: 0.7863   train/acc: 0.8557   valid/acc: 0.5641\n",
      "Epoch 40:  train/loss: 0.4010   valid/loss: 0.8038   train/acc: 0.8758   valid/acc: 0.5897\n",
      "Epoch 45:  train/loss: 0.3925   valid/loss: 0.8031   train/acc: 0.8758   valid/acc: 0.5641\n",
      "Epoch 50:  train/loss: 0.3849   valid/loss: 0.7961   train/acc: 0.8658   valid/acc: 0.5641\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "time_start = time()\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=5)\n",
    "time_end = time()\n",
    "elapsed = time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f124d0cc-880f-4fa5-b039-432229f53513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "test_acc = acc(model(df_test[\"tokenised\"]), jnp.array(list(df_test[\"labels\"])))\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d8ce05-5696-474e-8269-4761efb4888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  26.224316835403442\n"
     ]
    }
   ],
   "source": [
    "print(\"Time elapsed: \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad0923e-a291-4683-8fe1-c4add094a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"train_epoch_costs\": trainer.train_epoch_costs, \"train_acc\":trainer.train_results['acc'], \"val_costs\":trainer.val_costs, \"val_acc\":trainer.val_results['acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac13963-d031-4c8e-92c4-31214d658df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"./data/{N_QUBITS=},{LAYERS=},{BATCH_SIZE=},{EPOCHS=},{SEED=},{LEARNING_RATE=},{MAX_SENTENCE_WORDS=},{NR_FROM_EACH_CLASS=}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('python3.8': conda)",
   "language": "python",
   "name": "python3.8_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
